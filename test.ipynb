{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0a3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"tested.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236157b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop([\"PassengerId\", \"Name\", \"Cabin\",\"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82c8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510bc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee514e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Age\"] = X[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(titanic[\"Embarked\"].mode()[0])\n",
    "X[\"Fare\"] = X[\"Fare\"].fillna(titanic[\"Fare\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f9cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=[\"Sex\", \"Embarked\"], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdae22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc42269",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d6910db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred)) \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fce9a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Titanic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=10, out_features=15)\n",
    "        self.layer2 = nn.Linear(in_features=15, out_features=15)\n",
    "        self.layer3 = nn.Linear(in_features=15, out_features=1)\n",
    "\n",
    "    def forwad(self, x):\n",
    "        return self.layer3(self.layer2(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f80613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a9f6604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Titanic(\n",
       "  (layer1): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (layer2): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (layer3): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d908f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=10, out_features=15),\n",
    "    nn.Linear(in_features=15, out_features=15),\n",
    "    nn.Linear(in_features=15, out_features=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c241630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (1): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (2): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "548bafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss() \n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afef5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.5164755582809448 | Accuracy 72.75%| Test loss: 0.5201010704040527 | Test acc: 0.77%\n",
      "Epoch: 10 | Loss: 0.49479734897613525 | Accuracy 79.64%| Test loss: 0.4969012439250946 | Test acc: 0.85%\n",
      "Epoch: 20 | Loss: 0.47172629833221436 | Accuracy 85.93%| Test loss: 0.4722973108291626 | Test acc: 0.92%\n",
      "Epoch: 30 | Loss: 0.4472568929195404 | Accuracy 93.71%| Test loss: 0.4463144838809967 | Test acc: 0.98%\n",
      "Epoch: 40 | Loss: 0.421477735042572 | Accuracy 98.50%| Test loss: 0.41907942295074463 | Test acc: 0.99%\n",
      "Epoch: 50 | Loss: 0.39458218216896057 | Accuracy 98.80%| Test loss: 0.39082977175712585 | Test acc: 1.00%\n",
      "Epoch: 60 | Loss: 0.36687007546424866 | Accuracy 99.10%| Test loss: 0.3619115352630615 | Test acc: 1.00%\n",
      "Epoch: 70 | Loss: 0.33873695135116577 | Accuracy 99.40%| Test loss: 0.3327629268169403 | Test acc: 1.00%\n",
      "Epoch: 80 | Loss: 0.3106473386287689 | Accuracy 100.00%| Test loss: 0.3038817346096039 | Test acc: 1.00%\n",
      "Epoch: 90 | Loss: 0.2830953001976013 | Accuracy 100.00%| Test loss: 0.2757798433303833 | Test acc: 1.00%\n",
      "Epoch: 100 | Loss: 0.25655683875083923 | Accuracy 100.00%| Test loss: 0.24893292784690857 | Test acc: 1.00%\n",
      "Epoch: 110 | Loss: 0.231444850564003 | Accuracy 100.00%| Test loss: 0.22373545169830322 | Test acc: 1.00%\n",
      "Epoch: 120 | Loss: 0.20807501673698425 | Accuracy 100.00%| Test loss: 0.20047037303447723 | Test acc: 1.00%\n",
      "Epoch: 130 | Loss: 0.18664893507957458 | Accuracy 100.00%| Test loss: 0.17929807305335999 | Test acc: 1.00%\n",
      "Epoch: 140 | Loss: 0.1672549992799759 | Accuracy 100.00%| Test loss: 0.16026394069194794 | Test acc: 1.00%\n",
      "Epoch: 150 | Loss: 0.14988353848457336 | Accuracy 100.00%| Test loss: 0.14331838488578796 | Test acc: 1.00%\n",
      "Epoch: 160 | Loss: 0.13444960117340088 | Accuracy 100.00%| Test loss: 0.12834307551383972 | Test acc: 1.00%\n",
      "Epoch: 170 | Loss: 0.1208178922533989 | Accuracy 100.00%| Test loss: 0.11517706513404846 | Test acc: 1.00%\n",
      "Epoch: 180 | Loss: 0.10882491618394852 | Accuracy 100.00%| Test loss: 0.10363868623971939 | Test acc: 1.00%\n",
      "Epoch: 190 | Loss: 0.09829685837030411 | Accuracy 100.00%| Test loss: 0.09354247152805328 | Test acc: 1.00%\n",
      "Epoch: 200 | Loss: 0.08906189352273941 | Accuracy 100.00%| Test loss: 0.08470989018678665 | Test acc: 1.00%\n",
      "Epoch: 210 | Loss: 0.08095825463533401 | Accuracy 100.00%| Test loss: 0.07697614282369614 | Test acc: 1.00%\n",
      "Epoch: 220 | Loss: 0.07383842021226883 | Accuracy 100.00%| Test loss: 0.07019321620464325 | Test acc: 1.00%\n",
      "Epoch: 230 | Loss: 0.06757098436355591 | Accuracy 100.00%| Test loss: 0.06423069536685944 | Test acc: 1.00%\n",
      "Epoch: 240 | Loss: 0.062040556222200394 | Accuracy 100.00%| Test loss: 0.058975111693143845 | Test acc: 1.00%\n",
      "Epoch: 250 | Loss: 0.057147081941366196 | Accuracy 100.00%| Test loss: 0.054328810423612595 | Test acc: 1.00%\n",
      "Epoch: 260 | Loss: 0.05280430614948273 | Accuracy 100.00%| Test loss: 0.050208091735839844 | Test acc: 1.00%\n",
      "Epoch: 270 | Loss: 0.048938289284706116 | Accuracy 100.00%| Test loss: 0.046541519463062286 | Test acc: 1.00%\n",
      "Epoch: 280 | Loss: 0.04548575356602669 | Accuracy 100.00%| Test loss: 0.043268293142318726 | Test acc: 1.00%\n",
      "Epoch: 290 | Loss: 0.04239268973469734 | Accuracy 100.00%| Test loss: 0.04033656045794487 | Test acc: 1.00%\n",
      "Epoch: 300 | Loss: 0.03961287438869476 | Accuracy 100.00%| Test loss: 0.03770213574171066 | Test acc: 1.00%\n",
      "Epoch: 310 | Loss: 0.03710685297846794 | Accuracy 100.00%| Test loss: 0.035327352583408356 | Test acc: 1.00%\n",
      "Epoch: 320 | Loss: 0.03484082221984863 | Accuracy 100.00%| Test loss: 0.03318001702427864 | Test acc: 1.00%\n",
      "Epoch: 330 | Loss: 0.03278574347496033 | Accuracy 100.00%| Test loss: 0.03123253956437111 | Test acc: 1.00%\n",
      "Epoch: 340 | Loss: 0.030916664749383926 | Accuracy 100.00%| Test loss: 0.029461154714226723 | Test acc: 1.00%\n",
      "Epoch: 350 | Loss: 0.029212109744548798 | Accuracy 100.00%| Test loss: 0.02784552425146103 | Test acc: 1.00%\n",
      "Epoch: 360 | Loss: 0.02765347622334957 | Accuracy 100.00%| Test loss: 0.02636801265180111 | Test acc: 1.00%\n",
      "Epoch: 370 | Loss: 0.026224646717309952 | Accuracy 100.00%| Test loss: 0.02501332387328148 | Test acc: 1.00%\n",
      "Epoch: 380 | Loss: 0.02491161786019802 | Accuracy 100.00%| Test loss: 0.023768225684762 | Test acc: 1.00%\n",
      "Epoch: 390 | Loss: 0.023702193051576614 | Accuracy 100.00%| Test loss: 0.022621119394898415 | Test acc: 1.00%\n",
      "Epoch: 400 | Loss: 0.02258569560945034 | Accuracy 100.00%| Test loss: 0.02156198024749756 | Test acc: 1.00%\n",
      "Epoch: 410 | Loss: 0.021552765741944313 | Accuracy 100.00%| Test loss: 0.02058187499642372 | Test acc: 1.00%\n",
      "Epoch: 420 | Loss: 0.02059519849717617 | Accuracy 100.00%| Test loss: 0.019673096016049385 | Test acc: 1.00%\n",
      "Epoch: 430 | Loss: 0.019705746322870255 | Accuracy 100.00%| Test loss: 0.01882878504693508 | Test acc: 1.00%\n",
      "Epoch: 440 | Loss: 0.018878011032938957 | Accuracy 100.00%| Test loss: 0.018042853102087975 | Test acc: 1.00%\n",
      "Epoch: 450 | Loss: 0.018106287345290184 | Accuracy 100.00%| Test loss: 0.017309991642832756 | Test acc: 1.00%\n",
      "Epoch: 460 | Loss: 0.017385585233569145 | Accuracy 100.00%| Test loss: 0.01662537455558777 | Test acc: 1.00%\n",
      "Epoch: 470 | Loss: 0.016711384057998657 | Accuracy 100.00%| Test loss: 0.015984831377863884 | Test acc: 1.00%\n",
      "Epoch: 480 | Loss: 0.016079699620604515 | Accuracy 100.00%| Test loss: 0.015384522266685963 | Test acc: 1.00%\n",
      "Epoch: 490 | Loss: 0.01548693422228098 | Accuracy 100.00%| Test loss: 0.014821077696979046 | Test acc: 1.00%\n",
      "Epoch: 500 | Loss: 0.014929880388081074 | Accuracy 100.00%| Test loss: 0.014291438274085522 | Test acc: 1.00%\n",
      "Epoch: 510 | Loss: 0.014405644498765469 | Accuracy 100.00%| Test loss: 0.013792909681797028 | Test acc: 1.00%\n",
      "Epoch: 520 | Loss: 0.013911645859479904 | Accuracy 100.00%| Test loss: 0.013323030434548855 | Test acc: 1.00%\n",
      "Epoch: 530 | Loss: 0.013445510528981686 | Accuracy 100.00%| Test loss: 0.01287953369319439 | Test acc: 1.00%\n",
      "Epoch: 540 | Loss: 0.01300512719899416 | Accuracy 100.00%| Test loss: 0.012460521422326565 | Test acc: 1.00%\n",
      "Epoch: 550 | Loss: 0.012588594108819962 | Accuracy 100.00%| Test loss: 0.012064039707183838 | Test acc: 1.00%\n",
      "Epoch: 560 | Loss: 0.012194138020277023 | Accuracy 100.00%| Test loss: 0.01168851088732481 | Test acc: 1.00%\n",
      "Epoch: 570 | Loss: 0.011820174753665924 | Accuracy 100.00%| Test loss: 0.011332454159855843 | Test acc: 1.00%\n",
      "Epoch: 580 | Loss: 0.011465287767350674 | Accuracy 100.00%| Test loss: 0.010994460433721542 | Test acc: 1.00%\n",
      "Epoch: 590 | Loss: 0.01112811267375946 | Accuracy 100.00%| Test loss: 0.010673287324607372 | Test acc: 1.00%\n",
      "Epoch: 600 | Loss: 0.010807473212480545 | Accuracy 100.00%| Test loss: 0.01036777999252081 | Test acc: 1.00%\n",
      "Epoch: 610 | Loss: 0.010502268560230732 | Accuracy 100.00%| Test loss: 0.010076923295855522 | Test acc: 1.00%\n",
      "Epoch: 620 | Loss: 0.010211472399532795 | Accuracy 100.00%| Test loss: 0.009799789637327194 | Test acc: 1.00%\n",
      "Epoch: 630 | Loss: 0.009934174828231335 | Accuracy 100.00%| Test loss: 0.009535406716167927 | Test acc: 1.00%\n",
      "Epoch: 640 | Loss: 0.009669504128396511 | Accuracy 100.00%| Test loss: 0.009283040650188923 | Test acc: 1.00%\n",
      "Epoch: 650 | Loss: 0.0094166724011302 | Accuracy 100.00%| Test loss: 0.009041910991072655 | Test acc: 1.00%\n",
      "Epoch: 660 | Loss: 0.009174970909953117 | Accuracy 100.00%| Test loss: 0.008811368606984615 | Test acc: 1.00%\n",
      "Epoch: 670 | Loss: 0.008943712338805199 | Accuracy 100.00%| Test loss: 0.008590755052864552 | Test acc: 1.00%\n",
      "Epoch: 680 | Loss: 0.008722279220819473 | Accuracy 100.00%| Test loss: 0.008379451930522919 | Test acc: 1.00%\n",
      "Epoch: 690 | Loss: 0.008510101586580276 | Accuracy 100.00%| Test loss: 0.008176956325769424 | Test acc: 1.00%\n",
      "Epoch: 700 | Loss: 0.008306636475026608 | Accuracy 100.00%| Test loss: 0.007982753217220306 | Test acc: 1.00%\n",
      "Epoch: 710 | Loss: 0.008111432194709778 | Accuracy 100.00%| Test loss: 0.007796397432684898 | Test acc: 1.00%\n",
      "Epoch: 720 | Loss: 0.0079239746555686 | Accuracy 100.00%| Test loss: 0.007617419585585594 | Test acc: 1.00%\n",
      "Epoch: 730 | Loss: 0.007743871305137873 | Accuracy 100.00%| Test loss: 0.007445392198860645 | Test acc: 1.00%\n",
      "Epoch: 740 | Loss: 0.007570725865662098 | Accuracy 100.00%| Test loss: 0.007280033081769943 | Test acc: 1.00%\n",
      "Epoch: 750 | Loss: 0.0074041434563696384 | Accuracy 100.00%| Test loss: 0.007120891008526087 | Test acc: 1.00%\n",
      "Epoch: 760 | Loss: 0.007243811618536711 | Accuracy 100.00%| Test loss: 0.00696771964430809 | Test acc: 1.00%\n",
      "Epoch: 770 | Loss: 0.007089380174875259 | Accuracy 100.00%| Test loss: 0.006820122245699167 | Test acc: 1.00%\n",
      "Epoch: 780 | Loss: 0.006940568797290325 | Accuracy 100.00%| Test loss: 0.006677905097603798 | Test acc: 1.00%\n",
      "Epoch: 790 | Loss: 0.006797089707106352 | Accuracy 100.00%| Test loss: 0.00654073478654027 | Test acc: 1.00%\n",
      "Epoch: 800 | Loss: 0.006658665370196104 | Accuracy 100.00%| Test loss: 0.006408401764929295 | Test acc: 1.00%\n",
      "Epoch: 810 | Loss: 0.006525060161948204 | Accuracy 100.00%| Test loss: 0.006280648522078991 | Test acc: 1.00%\n",
      "Epoch: 820 | Loss: 0.006396046839654446 | Accuracy 100.00%| Test loss: 0.006157270632684231 | Test acc: 1.00%\n",
      "Epoch: 830 | Loss: 0.0062713888473808765 | Accuracy 100.00%| Test loss: 0.006038059946149588 | Test acc: 1.00%\n",
      "Epoch: 840 | Loss: 0.006150896195322275 | Accuracy 100.00%| Test loss: 0.005922811571508646 | Test acc: 1.00%\n",
      "Epoch: 850 | Loss: 0.0060343751683831215 | Accuracy 100.00%| Test loss: 0.005811323411762714 | Test acc: 1.00%\n",
      "Epoch: 860 | Loss: 0.005921658128499985 | Accuracy 100.00%| Test loss: 0.005703456234186888 | Test acc: 1.00%\n",
      "Epoch: 870 | Loss: 0.0058125220239162445 | Accuracy 100.00%| Test loss: 0.0055990396067500114 | Test acc: 1.00%\n",
      "Epoch: 880 | Loss: 0.005706873256713152 | Accuracy 100.00%| Test loss: 0.005497905425727367 | Test acc: 1.00%\n",
      "Epoch: 890 | Loss: 0.005604512523859739 | Accuracy 100.00%| Test loss: 0.005399931222200394 | Test acc: 1.00%\n",
      "Epoch: 900 | Loss: 0.0055053215473890305 | Accuracy 100.00%| Test loss: 0.0053049493581056595 | Test acc: 1.00%\n",
      "Epoch: 910 | Loss: 0.005409128963947296 | Accuracy 100.00%| Test loss: 0.005212889052927494 | Test acc: 1.00%\n",
      "Epoch: 920 | Loss: 0.0053158532828092575 | Accuracy 100.00%| Test loss: 0.005123569164425135 | Test acc: 1.00%\n",
      "Epoch: 930 | Loss: 0.005225346423685551 | Accuracy 100.00%| Test loss: 0.005036868620663881 | Test acc: 1.00%\n",
      "Epoch: 940 | Loss: 0.005137493368238211 | Accuracy 100.00%| Test loss: 0.004952731542289257 | Test acc: 1.00%\n",
      "Epoch: 950 | Loss: 0.005052168387919664 | Accuracy 100.00%| Test loss: 0.004871015902608633 | Test acc: 1.00%\n",
      "Epoch: 960 | Loss: 0.004969336092472076 | Accuracy 100.00%| Test loss: 0.004791622515767813 | Test acc: 1.00%\n",
      "Epoch: 970 | Loss: 0.004888836294412613 | Accuracy 100.00%| Test loss: 0.004714522510766983 | Test acc: 1.00%\n",
      "Epoch: 980 | Loss: 0.004810580983757973 | Accuracy 100.00%| Test loss: 0.004639517515897751 | Test acc: 1.00%\n",
      "Epoch: 990 | Loss: 0.004734523594379425 | Accuracy 100.00%| Test loss: 0.004566609859466553 | Test acc: 1.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # forward pass\n",
    "    y_logit = model(X_train)\n",
    "    # turn logits to pred probs to pred labels\n",
    "    y_pred = torch.round(torch.sigmoid(y_logit))\n",
    "        \n",
    "    # calculate the loss\n",
    "    loss = loss_fn(y_logit, y_train)\n",
    "    acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "    # optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # optimize step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### TESTING  \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # forward pass\n",
    "        test_logits = model(X_test)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        # calculate the tesr loss\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "        \n",
    "    # print out\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss} | Accuracy {acc:.2%}| Test loss: {test_loss} | Test acc: {test_acc:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d556a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77582041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
